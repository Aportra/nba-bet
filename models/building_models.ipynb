{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.linear_model._logistic import LogisticRegression\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.metrics import r2_score,make_scorer,mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import os\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_player_name(name):\n",
    "    \"\"\"Standardizes player names by removing special characters and handling known name variations.\"\"\"\n",
    "    name = name.lower().strip()  # Convert to lowercase & remove extra spaces\n",
    "    name = name.replace(\".\", \"\")  # Remove periods\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Remove special characters (apostrophes, dashes, etc.) \n",
    "    # Known name changes (add more as needed)\n",
    "    name_corrections = {\n",
    "        \"alexandre sarr\": \"alex sarr\",\n",
    "        \"jimmy butler\": \"jimmy butler iii\",\n",
    "        \"nicolas claxton\": \"nic claxton\",\n",
    "        \"kenyon martin jr\": \"kj martin\",\n",
    "        \"carlton carrington\": \"bub carrington\",\n",
    "        \"ron holland ii\": \"ronald holland ii\",\n",
    "        'cameron thomas':'cam thomas'\n",
    "    }\n",
    "\n",
    "    # Apply corrections if the name exists in the dictionary\n",
    "    return name_corrections.get(name, name)  # Default to original name if no correction found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#using shifted windows for rolling data to prevent data leakage\n",
    "player_query = f\"\"\" \n",
    "SELECT *\n",
    "from `capstone_data.player_modeling_data_partitioned`\n",
    "order by game_date asc\n",
    "\"\"\"\n",
    "\n",
    "team_query = f\"\"\"\n",
    "SELECT *\n",
    "from `capstone_data.team_modeling_data_partitioned`\n",
    "order by game_date asc\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36316/4285358681.py:2: DtypeWarning: Columns (126) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full_data = pd.read_csv('full_data.csv')\n"
     ]
    }
   ],
   "source": [
    " \n",
    "try:\n",
    "    full_data = pd.read_csv('full_data.csv')\n",
    "\n",
    "except:\n",
    "    nba_player_data = pd.DataFrame(pandas_gbq.read_gbq(player_query,project_id='miscellaneous-projects-444203',progress_bar_type='tqdm'))\n",
    "    team_data = pd.DataFrame(pandas_gbq.read_gbq(team_query,project_id='miscellaneous-projects-444203',progress_bar_type='tqdm'))\n",
    "    team_data  = team_data.merge(team_data,on='game_id',suffixes=('',\"_opponent\"))\n",
    "    team_data = team_data[team_data[\"team_id\"] != team_data[\"team_id_opponent\"]]\n",
    "    full_data = nba_player_data.merge(team_data, on = ['game_id','team'], how = 'inner',suffixes=('','remove'))\n",
    "    full_data.drop([column for column in full_data.columns if 'remove' in column],axis = 1 , inplace=True) \n",
    "    full_data.drop([column for column in full_data.columns if '_1' in column],axis = 1 , inplace=True)\n",
    "    full_data.to_csv('full_data.csv',mode = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordered = full_data.sort_values('game_date')\n",
    "\n",
    "data_ordered.dropna(inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Ideas \n",
    "\n",
    "* (ratio of 3pa and fga and 3pm and 3pa) TS% for players efg% \n",
    "* for players assist_to_turnover ratio assist ratio, \n",
    "* rebound_cahnce, defesnive reb %, \n",
    "* ast_ratio_season * pace, \n",
    "* home * pts season - data pts 3pm avg,\n",
    "* cold_streak pts_3gm_avg < pts_season boolean, \n",
    "* away difficulty away * opponent_defrtg_3gm_avg,\n",
    "* home_performance = data_ordered[data_ordered[\"home\"] == 1].groupby(\"team\")[\"pts_season\"].mean()\n",
    "* away_performance = data_ordered[data_ordered[\"away\"] == 1].groupby(\"team\")[\"pts_season\"].mean() these would be to see how the team performance changes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36316/3943372088.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_ordered = data_ordered.groupby(['player','season']).apply(lambda x: x.iloc[3:]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "data_ordered = data_ordered.groupby(['player','season']).apply(lambda x: x.iloc[3:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordered.sort_values(by='game_date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordered['game_date'] = pd.to_datetime(data_ordered['game_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordered['days_ago'] = (data_ordered['game_date'].max() - data_ordered['game_date']).dt.days\n",
    "data_ordered['time_decay_weight'] = 1 / (1 + np.log(1 + data_ordered['days_ago']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_ordered = data_ordered.drop('Unnamed: 0', axis =1)\n",
    "except KeyError:\n",
    "    print('Irregular column not made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs with the column mean, but only for numeric columns\n",
    "data_ordered.fillna(data_ordered.select_dtypes(include=['number']).mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = data_ordered.select_dtypes(include=['number']).columns.tolist()\n",
    "numeric_columns = [column for column in numeric_columns if column not in ['pts','reb','ast','blk','stl','3pm','game_id','game_date','days_ago','time_decay_weight','team_id', \"gp_rank\", \"w_rank\", \"l_rank\", \"w_pct_rank\", \"min_rank\", \"fgm_rank\",\n",
    "    \"fga_rank\", \"fg_pct_rank\", \"fg3m_rank\", \"fg3a_rank\", \"fg3_pct_rank\",\n",
    "    \"ftm_rank\", \"fta_rank\", \"ft_pct_rank\", \"oreb_rank\", \"dreb_rank\",\n",
    "    \"reb_rank\", \"ast_rank\", \"tov_rank\", \"stl_rank\", \"blk_rank\",\n",
    "    \"blka_rank\", \"pf_rank\", \"pfd_rank\", \"pts_rank\", \"plus_minus_rank\",]]\n",
    "\n",
    "numeric_columns = [feature for feature in numeric_columns if any(keyword in feature for keyword in [\"3gm_avg\", \"season\", \"momentum\"])]\n",
    "features = {feature:[] for feature in ['pts','reb','ast','3pm']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(data_ordered) * .80)\n",
    "\n",
    "train_data = data_ordered.iloc[:split_index]\n",
    "test_data = data_ordered[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for category in features.keys():\n",
    "    x = train_data[numeric_columns]\n",
    "    y = train_data[category]\n",
    "\n",
    "    mi_scores = mutual_info_regression(x, y)\n",
    "    mi_scores = pd.Series(mi_scores, index=numeric_columns)\n",
    "    selected_features = mi_scores[mi_scores > 0.10].index.tolist()  \n",
    "\n",
    "    features[category] = selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These values appeared to have non-linear relationships applying transformations\n",
    "# data_ordered['ft%_season'] = np.log1p(data_ordered['ft%_season'])\n",
    "# data_ordered['stl_3gm_avg'] = np.log1p(data_ordered['stl_3gm_avg'])\n",
    "# data_ordered['stl_season'] = np.log1p(data_ordered['stl_season'])\n",
    "# data_ordered['to_season'] = data_ordered['to_season']**2 \n",
    "# data_ordered['to_3gm_avg'] = data_ordered['to_3gm_avg']**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = {category:{} for category in ['pts','reb','ast','3pm']} \n",
    "saved_results = {category:{} for category in ['pts','reb','ast','3pm']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP\n",
    "Applying shap to help reduce collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for category in features.keys():\n",
    "\n",
    "    features_list = [f for f in features[category] if f != category]\n",
    "    print(len(features_list))\n",
    "    x_train,y_train = train_data[features_list],train_data[category]\n",
    "    x_test, y_test = test_data[features_list],test_data[category]\n",
    "    linear_model = LinearRegression()\n",
    "\n",
    "    linear_model.fit(x_train,y_train)\n",
    "\n",
    "    y_pred = linear_model.predict(x_test)\n",
    "    print(category)\n",
    "    print(r2_score(y_true=y_test,y_pred=y_pred))\n",
    "\n",
    "    saved_results[category]['linear_model']={'r2':{r2_score(y_true=y_test,y_pred=y_pred)}, 'mse':{mean_squared_error(y_true=y_test,y_pred=y_pred)}}\n",
    "    saved_models[category]['linear_model'] = linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in features.keys():\n",
    "    features_list = [f for f in features[category] if f != category]\n",
    "    x_train,y_train = train_data[features_list],train_data[category]\n",
    "    x_test, y_test = test_data[features_list],test_data[category]\n",
    "    ridge_model = Ridge(alpha=1)\n",
    "\n",
    "    ridge_model.fit(x_train,y_train)\n",
    "\n",
    "    output = pd.DataFrame({'prediction':ridge_model.predict(x_test), 'actual':y_test})\n",
    "    print(category)\n",
    "    print(r2_score(y_true=output['actual'],y_pred=output['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for category in features.keys():\n",
    "    features_list = features[category]\n",
    "\n",
    "    x_train, y_train = train_data[features_list], train_data[category]\n",
    "    x_test, y_test = test_data[features_list], test_data[category]\n",
    "\n",
    "    linear_model = Ridge(alpha=1.0)  # Use Ridge instead of LinearRegression\n",
    "    linear_model.fit(x_train, y_train)\n",
    "\n",
    "    # Cross-validation score instead of just test RÂ²\n",
    "    cv_r2 = cross_val_score(linear_model, x_train, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "    y_pred = linear_model.predict(x_test)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{category}: Cross-Val RÂ² = {cv_r2:.4f}, Test RÂ² = {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(data_ordered[numeric_columns])\n",
    "\n",
    "scaled_data_df = pd.DataFrame(scaled_data,columns=numeric_columns)\n",
    "\n",
    "split_index = int(len(data_ordered) * .80)\n",
    "\n",
    "scaled_train_data = scaled_data_df.iloc[:split_index]\n",
    "scaled_test_data = scaled_data_df[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[3,6,9],'learning_rate':[.01,.05,.1,.3],'booster':['gbtree','dart'],'subsample':[.5,.7,.9],'colsample_bytree':[.5,.7,.9],'n_estimators':[100,300,500]}\n",
    "param_linear = {'booster':['gblinear'],'lambda':[0,.1,1,10],'alpha':[0,.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgboost.XGBRegressor()\n",
    "mse_score = make_scorer(mean_squared_error,greater_is_better=False)\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "scoring = {'MSE':mse_score,'r2':r2_scorer}\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor,param_grid=param_grid,scoring = scoring,cv=tscv,n_jobs=1,verbose=0,refit='r2')\n",
    "grid_linear_search = GridSearchCV(estimator=xgb_regressor,param_grid=param_linear,scoring = scoring,cv=tscv,n_jobs=3,verbose=0,refit='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_features =  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in features.keys():\n",
    "    x_train,y_train = scaled_train_data[xg_features[category]],train_data[category]\n",
    "    x_test, y_test = scaled_test_data[xg_features[category]],test_data[category]\n",
    "\n",
    "    fit_params = {'eval_set':[(x_test,y_test)],'early_stopping_rounds':20,'verbose':False}\n",
    "\n",
    "    grid_linear_search.estimator.set_params(eval_metric='rmse')\n",
    "\n",
    "\n",
    "    grid_linear_search.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "    print(category)\n",
    "    print(grid_linear_search.best_params_)\n",
    "    print(grid_linear_search.best_score_)\n",
    "\n",
    "    y_pred = grid_linear_search.best_estimator_.predict(x_test)\n",
    "\n",
    "    saved_models[category]['XGboost'] = grid_linear_search.best_estimator_\n",
    "    saved_results[category]['XGboost']={'r2':{r2_score(y_true=y_test,y_pred=y_pred)}, 'mse':{mean_squared_error(y_true=y_test,y_pred=y_pred)}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "lgb_model = LGBMRegressor(n_estimators=1000, random_state=42,verbosity=-1)\n",
    "\n",
    "# Define the expanded parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [15, 31, 50, 75],\n",
    "    'learning_rate': [0.005, 0.01, 0.05],\n",
    "    'max_depth': [-1, 5, 10, 15],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Time series split (if your data is chronological)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Randomized search setup\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=40,  # control number of total combinations to test\n",
    "    cv=tscv,\n",
    "    scoring='r2',\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to your training data\n",
    "# Best model + params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(data_ordered) * .80)\n",
    "\n",
    "train_data = data_ordered.iloc[:split_index]\n",
    "test_data = data_ordered[split_index:]\n",
    "for category in features.keys():\n",
    "    x_train,y_train = train_data[features[category]],train_data[category]\n",
    "    x_test,y_test = test_data[features[category]],test_data[category]\n",
    "\n",
    "    random_search.fit(x_train,y_train)\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    print(category)\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "    y_pred = best_model.predict(x_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "    saved_models[category]['lightgbm'] = best_model\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'R2: {r2}')\n",
    "\n",
    "    saved_results[category]['lightgbm']={'r2':{r2_score(y_true=y_test,y_pred=y_pred)}, 'mse':{mean_squared_error(y_true=y_test,y_pred=y_pred)}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(saved_models,'models.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_performance.txt', 'w') as file:\n",
    "    for category, models in saved_results.items():\n",
    "        file.write(f\"Category: {category}\\n\")\n",
    "        for model, metrics in models.items():\n",
    "            file.write(f\"  Model: {model}\\n\")\n",
    "            for metric, value in metrics.items():\n",
    "                file.write(f\"    {metric}: {value}\\n\")\n",
    "        file.write(\"\\n\")  # Newline between categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Modeling into Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportra99/.local/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.5.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Ensemble modeling\n",
    "\n",
    "saved_models = joblib.load('models.pkl')\n",
    "\n",
    "linear_models = {cat: saved_models[cat]['linear_model'] for cat in saved_models if 'linear_model' in saved_models[cat]}\n",
    "lightgbm_models = {cat: saved_models[cat]['lightgbm'] for cat in saved_models if 'lightgbm' in saved_models[cat]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts Meta-model RÂ²: 0.6164, MSE: 30.4233\n",
      "reb Meta-model RÂ²: 0.5308, MSE: 5.6493\n",
      "ast Meta-model RÂ²: 0.5695, MSE: 3.0275\n",
      "3pm Meta-model RÂ²: 0.4488, MSE: 1.2632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "meta_models = {}\n",
    "meta_results = {}\n",
    "\n",
    "for category in ['pts', 'reb', 'ast', '3pm']:\n",
    "    # Load models\n",
    "    lm = saved_models[category]['linear_model']\n",
    "    lgb = saved_models[category]['lightgbm']\n",
    "\n",
    "    # Prepare test data\n",
    "    lm_features_list = [f.strip() for f in lm.feature_names_in_]\n",
    "    lgb_features_list = [f.strip() for f in lgb.feature_names_in_]\n",
    "\n",
    "    lm_x_test = test_data[lm_features_list]\n",
    "\n",
    "    lgb_x_test = test_data[lgb_features_list]\n",
    "\n",
    "    y_test = test_data[category]\n",
    "\n",
    "    # Get predictions\n",
    "    preds_lm = lm.predict(lm_x_test)\n",
    "    preds_lgb = lgb.predict(lgb_x_test)\n",
    "\n",
    "    # Stack predictions into meta-model features\n",
    "    meta_X = np.vstack([preds_lm, preds_lgb]).T\n",
    "    meta_y = y_test.values\n",
    "\n",
    "    # Train meta-model\n",
    "    meta_model = Ridge()\n",
    "    meta_model.fit(meta_X, meta_y)\n",
    "\n",
    "    # Evaluate meta-model\n",
    "    meta_preds = meta_model.predict(meta_X)\n",
    "    r2 = r2_score(meta_y, meta_preds)\n",
    "    mse = mean_squared_error(meta_y, meta_preds)\n",
    "\n",
    "    print(f\"{category} Meta-model RÂ²: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "    meta_models[category] = meta_model\n",
    "    meta_results[category] = {'r2': r2, 'mse': mse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(meta_models,'meta_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTS Meta-Model Weights:\n",
      "  Linear Model Weight:  -0.1503\n",
      "  LightGBM Weight:      1.1462\n",
      "REB Meta-Model Weights:\n",
      "  Linear Model Weight:  0.1157\n",
      "  LightGBM Weight:      0.8922\n",
      "AST Meta-Model Weights:\n",
      "  Linear Model Weight:  0.1427\n",
      "  LightGBM Weight:      0.8560\n",
      "3PM Meta-Model Weights:\n",
      "  Linear Model Weight:  -0.2429\n",
      "  LightGBM Weight:      1.2381\n"
     ]
    }
   ],
   "source": [
    "coef = {}\n",
    "for category, model in meta_models.items():\n",
    "    coef_linear, coef_lgbm = model.coef_\n",
    "    print(f\"{category.upper()} Meta-Model Weights:\")\n",
    "    print(f\"  Linear Model Weight:  {coef_linear:.4f}\")\n",
    "    print(f\"  LightGBM Weight:      {coef_lgbm:.4f}\")\n",
    "\n",
    "    coef[f'{category}_lm'] = coef_linear\n",
    "    coef[f'{category}_lgb'] = coef_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Model into Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_profit(pred, actual, odds):\n",
    "    if pred == actual:\n",
    "        return 100 if odds < 0 else odds\n",
    "    else:\n",
    "        return -abs(odds) if odds < 0 else -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportra99/.local/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m|\n",
      "Downloading: 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m|\n",
      "Downloading: 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m|\n",
      "Downloading: 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m|\n"
     ]
    }
   ],
   "source": [
    "cats = ['points','assists','rebounds','threes_made']\n",
    "categories = ['pts','ast','reb','3pm']\n",
    "odds_data = {}\n",
    "for cat,category in zip(cats,categories):\n",
    "    predictions_query = f\"\"\"\n",
    "    select \n",
    "        po.*,\n",
    "        pp.Over,\n",
    "        pp.Under,\n",
    "        pp.{category}_linear_model,\n",
    "        pp.{category}_lightgbm\n",
    "    from `capstone_data.{cat}_predictions` pp\n",
    "    inner join `capstone_data.{category}_outcome` po\n",
    "        on pp.Player = po.player and date(pp.Date_Updated) = po.game_date\n",
    "    where pp.{category}_linear_model is not null\n",
    "    \"\"\" \n",
    "    data = pandas_gbq.read_gbq(predictions_query,project_id='miscellaneous-projects-444203')\n",
    "\n",
    "    \n",
    "    odds_data[category] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-03-28 00:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ordered['game_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = {category:[] for category in categories}\n",
    "\n",
    "data_ordered['player'] = data_ordered['player'].apply(clean_player_name)\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    data = odds_data[category]\n",
    "    \n",
    "    data['game_date'] = pd.to_datetime(data['game_date'])\n",
    "\n",
    "    data['player']= data['player'].apply(clean_player_name)\n",
    "\n",
    "    data = data.merge(data_ordered, on=['player','game_date'],how='inner')\n",
    "\n",
    "    data = data.drop_duplicates(subset=['player', 'game_date'], keep='first')\n",
    "\n",
    "    full_data[category] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat,category in zip(cats,categories):\n",
    "    full_data[category][f'{category}_ensemble'] = (pd.to_numeric(full_data[category][f'{category}_linear_model']) * \n",
    "    coef[f'{category}_lm'] + pd.to_numeric(full_data[category][f'{category}_lightgbm'] * coef[f'{category}_lgb']))\n",
    "\n",
    "    full_data[category][f'{category}_delta'] = full_data[category][f'{cat}'] - full_data[category][f'{category}_ensemble']\n",
    "\n",
    "    full_data[category].sort_values(by='game_date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing category: PTS ===\n",
      "Top averaged MI features for PTS:\n",
      "['pts_lightgbm', 'plus_minus_momentum', 'pts_momentum', 'fga_momentum', 'ftm_season', 'dreb_momentum', 'fg3m_3gm_avg', 'ft_pct_momentum', 'fg_pct_momentum', 'pts_3gm_avg', 'fg3a_season', 'pts_season', 'dreb_opponent', 'fta_momentum', 'ft_pct_3gm_avg']\n",
      "\n",
      "=== Processing category: AST ===\n",
      "Top averaged MI features for AST:\n",
      "['oreb_season', 'ftm_season', 'reb_momentum', 'ast_lightgbm', 'fg3a_season', 'oreb_momentum', 'pts_season', 'dreb_momentum', 'min_3gm_avg', 'fg_pct_3gm_avg', 'pf_3gm_avg', 'min_season', 'fta_season_opponent', 'pf_3gm_avg_opponent', 'ast_3gm_avg']\n",
      "\n",
      "=== Processing category: REB ===\n",
      "Top averaged MI features for REB:\n",
      "['ftm_season', 'fta_momentum', 'blk_momentum', 'reb_linear_model', 'fta_3gm_avg', 'fg3m_season', 'dreb_season', 'fg_pct_season', 'pts_opponent', 'fg3a_season', 'oreb_3gm_avg', 'fta_season_opponent', 'reb_lightgbm', 'ftm_3gm_avg', 'ft_pct_momentum']\n",
      "\n",
      "=== Processing category: 3PM ===\n",
      "Top averaged MI features for 3PM:\n",
      "['dreb_momentum', 'ast_momentum', 'ftm_season', 'fg3_pct_momentum', 'blk_season', 'fg3m', 'fg3_pct_season', 'ftm_opponent', 'pf_season', 'to_season', 'to_momentum', 'blk_momentum', 'threes_made', 'fta_season', 'fg_pct_season']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "classification_features = {}\n",
    "mi_feature_sets = {}\n",
    "categories = ['pts', 'ast', 'reb', '3pm']\n",
    "\n",
    "box_score_cols = [\n",
    "    'pts', 'pts_y', 'pts_x', 'ast_x', 'ast_y', 'reb_x', 'reb_y', 'reb', 'ast',\n",
    "    'stl', 'blk', 'to', 'pf', 'min', 'fgm', 'fga', 'fg_pct',\n",
    "    '3pm_y', 'fg3a', 'fg3_pct', 'ftm', 'fta', 'ft_pct',\n",
    "    'oreb', 'dreb', 'plus_minus', '3pm', '3pm_x'\n",
    "]\n",
    "exclude_cols = box_score_cols + ['result', 'player', 'game_date', 'team', 'team_city', 'matchup', 'matchup_opponent']\n",
    "\n",
    "NUM_RUNS = 10\n",
    "SEEDS = list(range(42, 42 + NUM_RUNS))\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"\\n=== Processing category: {category.upper()} ===\")\n",
    "    data = full_data[category].copy()\n",
    "\n",
    "    if isinstance(data['result'].iloc[0], str):\n",
    "        data['result'] = data['result'].map({'Over': 1, 'Under': 0})\n",
    "\n",
    "    data = data.dropna(subset=['result'])\n",
    "\n",
    "    # Define features\n",
    "    candidate_features = [col for col in data.columns if col not in exclude_cols]\n",
    "    numeric_features = [col for col in candidate_features if pd.api.types.is_numeric_dtype(data[col])]\n",
    "\n",
    "    X = data[numeric_features].fillna(0)\n",
    "    y = data['result']\n",
    "\n",
    "    # âž¤ Split first (no shuffle to preserve game ordering if time-based)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    # âž¤ Standard scale only on training set\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # âž¤ MI on training data only\n",
    "    mi_matrix = []\n",
    "    for seed in SEEDS:\n",
    "        mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=seed)\n",
    "        mi_matrix.append(mi_scores)\n",
    "\n",
    "    mi_avg_scores = np.mean(mi_matrix, axis=0)\n",
    "    mi_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Avg_MI_Score': mi_avg_scores\n",
    "    }).sort_values(by='Avg_MI_Score', ascending=False)\n",
    "\n",
    "    # âž¤ Select top 15 features\n",
    "    top_features = mi_df['Feature'].head(15).tolist()\n",
    "    mi_feature_sets[category] = top_features\n",
    "    classification_features[category] = top_features\n",
    "\n",
    "    print(f\"Top averaged MI features for {category.upper()}:\")\n",
    "    print(top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model: RandomForest ===\n",
      "\n",
      "--- Category: PTS ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     293     |  0.5358 |    56.00  |    0.18\n",
      "    0.60     |     0.40     |     284     |  0.5423 |   406.00  |    1.34\n",
      "    0.65     |     0.35     |     276     |  0.5507 |   916.00  |    3.11\n",
      "    0.70     |     0.30     |     267     |  0.5468 |   666.00  |    2.33\n",
      "    0.75     |     0.25     |     255     |  0.5333 |   -119.00  |   -0.44\n",
      "\n",
      "--- Category: AST ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     206     |  0.5000 |   -1765.00  |   -7.54\n",
      "    0.60     |     0.40     |     196     |  0.5102 |   -1247.00  |   -5.61\n",
      "    0.65     |     0.35     |     190     |  0.5000 |   -1606.00  |   -7.45\n",
      "    0.70     |     0.30     |     177     |  0.5085 |   -1152.00  |   -5.75\n",
      "    0.75     |     0.25     |     168     |  0.5179 |   -766.00  |   -4.02\n",
      "\n",
      "--- Category: REB ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     282     |  0.5106 |   -1356.00  |   -4.32\n",
      "    0.60     |     0.40     |     267     |  0.5131 |   -1126.00  |   -3.79\n",
      "    0.65     |     0.35     |     256     |  0.5078 |   -1381.00  |   -4.83\n",
      "    0.70     |     0.30     |     245     |  0.5102 |   -1175.00  |   -4.30\n",
      "    0.75     |     0.25     |     230     |  0.5174 |   -815.00  |   -3.18\n",
      "\n",
      "--- Category: 3PM ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     197     |  0.5533 |   504.00  |    2.25\n",
      "    0.60     |     0.40     |     190     |  0.5632 |   878.00  |    4.07\n",
      "    0.65     |     0.35     |     185     |  0.5676 |   1108.00  |    5.30\n",
      "    0.70     |     0.30     |     175     |  0.5771 |   1497.00  |    7.60\n",
      "    0.75     |     0.25     |     163     |  0.5706 |   1220.00  |    6.64\n",
      "\n",
      "=== Model: LogisticRegression ===\n",
      "\n",
      "--- Category: PTS ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     188     |  0.5638 |   1235.00  |    6.18\n",
      "    0.60     |     0.40     |      90     |  0.6333 |   2015.00  |   21.41\n",
      "    0.65     |     0.35     |      42     |  0.6190 |   785.00  |   17.78\n",
      "    0.70     |     0.30     |      15     |  0.5333 |    -5.00  |   -0.31\n",
      "    0.75     |     0.25     |       8     |  0.7500 |   375.00  |   45.45\n",
      "\n",
      "--- Category: AST ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     133     |  0.5489 |   594.00  |    4.03\n",
      "    0.60     |     0.40     |      55     |  0.5818 |   620.00  |   10.25\n",
      "    0.65     |     0.35     |      21     |  0.6667 |   619.00  |   27.22\n",
      "    0.70     |     0.30     |       3     |  0.6667 |    75.00  |   22.39\n",
      "    0.75     |     0.25     |       2     |  1.0000 |   210.00  |  105.00\n",
      "\n",
      "--- Category: REB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aportra99/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     137     |  0.5693 |   1272.00  |    8.59\n",
      "    0.60     |     0.40     |      47     |  0.5319 |    88.00  |    1.73\n",
      "    0.65     |     0.35     |      14     |  0.7143 |   608.00  |   41.64\n",
      "    0.70     |     0.30     |       3     |  0.6667 |    85.00  |   26.98\n",
      "\n",
      "--- Category: 3PM ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     160     |  0.6375 |   4113.00  |   23.52\n",
      "    0.60     |     0.40     |     117     |  0.6496 |   3264.00  |   25.50\n",
      "    0.65     |     0.35     |      80     |  0.7250 |   3589.00  |   41.66\n",
      "    0.70     |     0.30     |      45     |  0.7556 |   2324.00  |   48.97\n",
      "    0.75     |     0.25     |      29     |  0.8276 |   1955.00  |   65.60\n",
      "\n",
      "=== Model: LightGBM ===\n",
      "\n",
      "--- Category: PTS ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     302     |  0.5033 |   -2079.00  |   -6.40\n",
      "    0.60     |     0.40     |     299     |  0.5017 |   -2179.00  |   -6.77\n",
      "    0.65     |     0.35     |     289     |  0.5017 |   -2069.00  |   -6.65\n",
      "    0.70     |     0.30     |     284     |  0.5106 |   -1489.00  |   -4.88\n",
      "    0.75     |     0.25     |     271     |  0.5166 |   -1079.00  |   -3.71\n",
      "\n",
      "--- Category: AST ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     206     |  0.5825 |   2237.00  |    9.77\n",
      "    0.60     |     0.40     |     203     |  0.5813 |   2182.00  |    9.67\n",
      "    0.65     |     0.35     |     195     |  0.5692 |   1563.00  |    7.19\n",
      "    0.70     |     0.30     |     191     |  0.5654 |   1398.00  |    6.56\n",
      "    0.75     |     0.25     |     186     |  0.5591 |   1108.00  |    5.33\n",
      "\n",
      "--- Category: REB ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     289     |  0.5363 |    52.00  |    0.16\n",
      "    0.60     |     0.40     |     282     |  0.5248 |   -653.00  |   -2.08\n",
      "    0.65     |     0.35     |     266     |  0.5226 |   -640.00  |   -2.16\n",
      "    0.70     |     0.30     |     253     |  0.5257 |   -399.00  |   -1.42\n",
      "    0.75     |     0.25     |     234     |  0.5385 |   312.00  |    1.20\n",
      "\n",
      "--- Category: 3PM ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     202     |  0.5941 |   2536.00  |   11.16\n",
      "    0.60     |     0.40     |     198     |  0.5909 |   2402.00  |   10.79\n",
      "    0.65     |     0.35     |     195     |  0.5897 |   2303.00  |   10.49\n",
      "    0.70     |     0.30     |     187     |  0.5989 |   2583.00  |   12.28\n",
      "    0.75     |     0.25     |     172     |  0.5988 |   2248.00  |   11.63\n",
      "\n",
      "=== Model: Stacked ===\n",
      "\n",
      "--- Category: PTS ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     297     |  0.5286 |   -329.00  |   -1.04\n",
      "    0.60     |     0.40     |     277     |  0.5199 |   -834.00  |   -2.81\n",
      "    0.65     |     0.35     |     265     |  0.5245 |   -554.00  |   -1.95\n",
      "    0.70     |     0.30     |     240     |  0.5375 |   101.00  |    0.39\n",
      "    0.75     |     0.25     |     215     |  0.5581 |   1006.00  |    4.37\n",
      "\n",
      "--- Category: AST ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     197     |  0.5431 |   323.00  |    1.46\n",
      "    0.60     |     0.40     |     189     |  0.5397 |   163.00  |    0.77\n",
      "    0.65     |     0.35     |     175     |  0.5486 |   478.00  |    2.42\n",
      "    0.70     |     0.30     |     167     |  0.5569 |   703.00  |    3.73\n",
      "    0.75     |     0.25     |     151     |  0.5430 |   128.00  |    0.75\n",
      "\n",
      "--- Category: REB ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     283     |  0.5300 |   -86.00  |   -0.27\n",
      "    0.60     |     0.40     |     272     |  0.5331 |    59.00  |    0.20\n",
      "    0.65     |     0.35     |     265     |  0.5321 |    28.00  |    0.10\n",
      "    0.70     |     0.30     |     254     |  0.5433 |   573.00  |    2.04\n",
      "    0.75     |     0.25     |     238     |  0.5378 |   268.00  |    1.01\n",
      "\n",
      "--- Category: 3PM ---\n",
      "Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\n",
      "---------------------------------------------------------------------------\n",
      "    0.55     |     0.45     |     199     |  0.5528 |   638.00  |    2.83\n",
      "    0.60     |     0.40     |     188     |  0.5532 |   643.00  |    3.02\n",
      "    0.65     |     0.35     |     173     |  0.5549 |   678.00  |    3.46\n",
      "    0.70     |     0.30     |     167     |  0.5509 |   508.00  |    2.68\n",
      "    0.75     |     0.25     |     157     |  0.5478 |   378.00  |    2.12\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "THRESH_OVER = 0.65\n",
    "THRESH_UNDER = 0.35\n",
    "label_map = {'Over': 1, 'Under': 0}\n",
    "\n",
    "# Define model options\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=150, max_depth=8, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42),\n",
    "    'Stacked': StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "            ('lgbm', LGBMClassifier(n_estimators=100, random_state=42)),\n",
    "        ],\n",
    "        final_estimator=LogisticRegression()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results = {}\n",
    "\n",
    "# Helper for American odds payout\n",
    "def compute_profit(pred, actual, odds):\n",
    "    if pred == actual:\n",
    "        return 100 if odds < 0 else odds\n",
    "    else:\n",
    "        return -abs(odds) if odds < 0 else -100\n",
    "\n",
    "# Loop through models and categories\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Model: {model_name} ===\")\n",
    "    results[model_name] = {}\n",
    "    \n",
    "    for category in ['pts', 'ast', 'reb', '3pm']:\n",
    "        print(f\"\\n--- Category: {category.upper()} ---\")\n",
    "        df = full_data[category].copy()\n",
    "        df = df.dropna(subset=['result'])\n",
    "        df['result'] = df['result'].map(label_map) if df['result'].dtype == object else df['result']\n",
    "\n",
    "        x = df[classification_features[category]].fillna(0)\n",
    "        y = df['result']\n",
    "        over_odds = df['Over'].values\n",
    "        under_odds = df['Under'].values\n",
    "\n",
    "        # Train-test split\n",
    "        x_train, x_test, y_train, y_test, over_train, over_test, under_train, under_test = train_test_split(\n",
    "            x, y, over_odds, under_odds, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Fit + calibrate\n",
    "        base_model = model\n",
    "        base_model.fit(x_train, y_train)\n",
    "        calibrated_model = CalibratedClassifierCV(base_model, cv='prefit')\n",
    "        calibrated_model.fit(x_train, y_train)\n",
    "        y_prob = calibrated_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "        # Thresholds to simulate\n",
    "        thresholds = [(0.5 + i * 0.05, 0.5 - i * 0.05) for i in range(1, 6)]\n",
    "\n",
    "        print(\"Threshold_Over | Threshold_Under | Bets_Placed | Accuracy | Profit ($) | ROI (%)\")\n",
    "        print(\"-\" * 75)\n",
    "\n",
    "        for over_thresh, under_thresh in thresholds:\n",
    "            bets = []\n",
    "            actuals = []\n",
    "            odds_used = []\n",
    "\n",
    "            for prob, actual, o, u in zip(y_prob, y_test, over_test, under_test):\n",
    "                if prob >= over_thresh:\n",
    "                    bets.append(1)\n",
    "                    actuals.append(actual)\n",
    "                    odds_used.append(o)\n",
    "                elif prob <= under_thresh:\n",
    "                    bets.append(0)\n",
    "                    actuals.append(actual)\n",
    "                    odds_used.append(u)\n",
    "\n",
    "            if not bets:\n",
    "                continue\n",
    "\n",
    "            # Calculate profit per bet\n",
    "            profits = [compute_profit(p, a, odd) for p, a, odd in zip(bets, actuals, odds_used)]\n",
    "            total_profit = sum(profits)\n",
    "            total_risk = sum(abs(odd) if p != a else 100 for p, a, odd in zip(bets, actuals, odds_used))  # optional\n",
    "            roi = (total_profit / total_risk) * 100 if total_risk > 0 else 0\n",
    "            accuracy = sum([p == a for p, a in zip(bets, actuals)]) / len(bets)\n",
    "\n",
    "            print(f\"    {over_thresh:.2f}     |     {under_thresh:.2f}     |    {len(bets):4}     |  {accuracy:.4f} |   {total_profit:6.2f}  |  {roi:6.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“… Latest date used in regression training (data_ordered): 2023-04-09\n",
      "\n",
      "ðŸš¨ Checking for potential overlap between regression training and classification test sets:\n",
      "\n",
      "âœ… PTS: Clean split â€” Regression ends 2023-04-09, classification test starts 2025-03-03\n",
      "âœ… AST: Clean split â€” Regression ends 2023-04-09, classification test starts 2025-03-03\n",
      "âœ… REB: Clean split â€” Regression ends 2023-04-09, classification test starts 2025-03-03\n",
      "âœ… 3PM: Clean split â€” Regression ends 2023-04-09, classification test starts 2025-03-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36316/293419545.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['game_date'] = pd.to_datetime(train_data['game_date'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Categories\n",
    "categories = ['pts', 'ast', 'reb', '3pm']\n",
    "\n",
    "# --- STEP 1: Get Latest Regression Date from `data_ordered`\n",
    "train_data['game_date'] = pd.to_datetime(train_data['game_date'])\n",
    "regression_cutoff_date = train_data['game_date'].max()\n",
    "\n",
    "print(f\"ðŸ“… Latest date used in regression training (data_ordered): {regression_cutoff_date.date()}\")\n",
    "\n",
    "# --- STEP 2: Get Earliest Test Date per Category\n",
    "test_start_dates = {}\n",
    "\n",
    "for category in categories:\n",
    "    df = full_data[category].copy()\n",
    "    df = df.dropna(subset=['result'])\n",
    "    df = df.sort_values('game_date')  # Just in case\n",
    "\n",
    "    x = df[classification_features[category]].fillna(0)\n",
    "    y = df['result']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    test_dates = df.loc[x_test.index, 'game_date']\n",
    "    test_start_dates[category] = test_dates.min()\n",
    "\n",
    "# --- STEP 3: Check for Overlap\n",
    "print(\"\\nðŸš¨ Checking for potential overlap between regression training and classification test sets:\\n\")\n",
    "for cat in categories:\n",
    "    test_date = test_start_dates[cat]\n",
    "    if regression_cutoff_date >= test_date:\n",
    "        print(f\"âš ï¸ {cat.upper()}: OVERLAP detected â€” Regression trained up to {regression_cutoff_date.date()}, classification test starts {test_date.date()}\")\n",
    "    else:\n",
    "        print(f\"âœ… {cat.upper()}: Clean split â€” Regression ends {regression_cutoff_date.date()}, classification test starts {test_date.date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
